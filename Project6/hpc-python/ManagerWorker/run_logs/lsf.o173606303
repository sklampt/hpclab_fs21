Sender: LSF System <lsfadmin@eu-a2p-139>
Subject: Job 173606303: <mpirun python3 manager_worker.py 4001 4001 100> in cluster <euler> Exited

Job <mpirun python3 manager_worker.py 4001 4001 100> was submitted from host <eu-login-11> by user <sklampt> in cluster <euler> at Thu May 27 21:59:09 2021
Job was executed on host(s) <4*eu-a2p-139>, in queue <normal.4h>, as user <sklampt> in cluster <euler> at Thu May 27 21:59:17 2021
</cluster/home/sklampt> was used as the home directory.
</cluster/home/sklampt/hpclab/hpclab_fs2021/Project6/hpc-python/ManagerWorker> was used as the working directory.
Started at Thu May 27 21:59:17 2021
Terminated at Thu May 27 21:59:19 2021
Results reported at Thu May 27 21:59:19 2021

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
mpirun python3 manager_worker.py 4001 4001 100
------------------------------------------------------------

Exited with exit code 1.

Resource usage summary:

    CPU time :                                   0.47 sec.
    Max Memory :                                 6 MB
    Average Memory :                             -
    Total Requested Memory :                     4096.00 MB
    Delta Memory :                               4090.00 MB
    Max Swap :                                   -
    Max Processes :                              -
    Max Threads :                                -
    Run time :                                   24 sec.
    Turnaround time :                            10 sec.

The output (if any) follows:

[eu-a2p-139:94174] mca_base_component_repository_open: shmem "/cluster/apps/openmpi/1.6.5/x86_64/gcc_6.3.0/lib/openmpi/mca_shmem_mmap" uses an MCA interface that is not recognized (component MCA v2.0.0 != supported MCA v2.1.0) -- ignored
[eu-a2p-139:94174] mca_base_component_repository_open: unable to open mca_shmem_posix: /cluster/apps/openmpi/1.6.5/x86_64/gcc_6.3.0/lib/openmpi/mca_shmem_posix.so: undefined symbol: opal_shmem_base_output (ignored)
[eu-a2p-139:94174] mca_base_component_repository_open: shmem "/cluster/apps/openmpi/1.6.5/x86_64/gcc_6.3.0/lib/openmpi/mca_shmem_sysv" uses an MCA interface that is not recognized (component MCA v2.0.0 != supported MCA v2.1.0) -- ignored
--------------------------------------------------------------------------
It looks like opal_init failed for some reason; your parallel process is
likely to abort.  There are many reasons that a parallel process can
fail during opal_init; some of which are due to configuration or
environment problems.  This failure appears to be an internal failure;
here's some additional information (which may only be relevant to an
Open MPI developer):

  opal_shmem_base_select failed
  --> Returned value -1 instead of OPAL_SUCCESS
--------------------------------------------------------------------------
